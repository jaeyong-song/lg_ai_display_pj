{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Full Model with Vt_Pretrained MLP Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load Vt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VtMLP(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VtMLP(nn.Module):\n",
    "  '''\n",
    "    Multilayer Perceptron for regression.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(5, 64),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(64, 32),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(32, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''\n",
    "      Forward pass\n",
    "    '''\n",
    "    return self.layers(x)\n",
    "\n",
    "vt_model = VtMLP()\n",
    "vt_model.load_state_dict(torch.load('../checkpoint/vt_mlp_model.pt'))\n",
    "vt_model.eval() # we pretrained this model... so we'll use this model for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Make dataset for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullWithVtDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, scale_data=True):\n",
    "        if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
    "            if scale_data:\n",
    "                X = StandardScaler().fit_transform(X)\n",
    "            vt = vt_model(torch.Tensor(X)).detach().numpy()\n",
    "            X = np.concatenate([X, vt], 1)\n",
    "            self.X = torch.from_numpy(X)\n",
    "            self.y = torch.from_numpy(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86832"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_csv('../data_full/full_dataset.csv')\n",
    "len(full_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86832\n",
      "86832\n",
      "86832\n"
     ]
    }
   ],
   "source": [
    "full_X = full_df[['W','L','T','Vgs','Vds']].to_numpy()\n",
    "print(len(full_X))\n",
    "full_y = full_df[['Ids']].to_numpy()\n",
    "print(len(full_y))\n",
    "dataset = FullWithVtDataset(full_X, full_y)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(dataset, [69466,17366])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, num_workers=1)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Make Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FullWithVtMLP(nn.Module):\n",
    "    '''\n",
    "    Multilayer Perceptron for regression.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Linear(6, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Forward pass\n",
    "        '''\n",
    "        return self.layers(x)\n",
    "\n",
    "mlp = FullWithVtMLP().to(device)\n",
    "# mlp.load_state_dict(torch.load('../checkpoint/full_vt_mlp_model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Set Loss and Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NRMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "    def forward(self, y_hat, y):\n",
    "        log_abs_y_hat = torch.log(torch.abs(y_hat))\n",
    "        log_abs_y = torch.log(torch.abs(y))\n",
    "        log_abs_delta = log_abs_y_hat - log_abs_y\n",
    "        delta = y_hat - y\n",
    "        # return torch.sqrt(torch.mean(log_abs_delta/log_abs_y)**2+self.eps)\n",
    "        return torch.sqrt(torch.mean(log_abs_delta/log_abs_y)**2+self.eps) + torch.sqrt(torch.mean(delta/y)**2+self.eps)\n",
    "\n",
    "loss_function = NRMSELoss()\n",
    "# loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(mlp.parameters(), lr=1e-4, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-4, \n",
    "                                              step_size_up=5, max_lr=1e-4, \n",
    "                                              gamma=0.5, mode='exp_range')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 152599019.520\n",
      "Loss after mini-batch  1001: nan\n",
      "Loss after mini-batch  2001: nan\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: nan\n",
      "Loss after mini-batch  1001: nan\n",
      "Loss after mini-batch  2001: nan\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/nfs/home/seonbinara/lg_display_pj/training/full_MLP_regression.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacsys15.yonsei.ac.kr/nfs/home/seonbinara/lg_display_pj/training/full_MLP_regression.ipynb#ch0000015vscode-remote?line=17'>18</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacsys15.yonsei.ac.kr/nfs/home/seonbinara/lg_display_pj/training/full_MLP_regression.ipynb#ch0000015vscode-remote?line=19'>20</a>\u001b[0m \u001b[39m# Perform forward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bacsys15.yonsei.ac.kr/nfs/home/seonbinara/lg_display_pj/training/full_MLP_regression.ipynb#ch0000015vscode-remote?line=20'>21</a>\u001b[0m outputs \u001b[39m=\u001b[39m mlp(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacsys15.yonsei.ac.kr/nfs/home/seonbinara/lg_display_pj/training/full_MLP_regression.ipynb#ch0000015vscode-remote?line=22'>23</a>\u001b[0m \u001b[39m# Compute loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacsys15.yonsei.ac.kr/nfs/home/seonbinara/lg_display_pj/training/full_MLP_regression.ipynb#ch0000015vscode-remote?line=23'>24</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(outputs, targets)\n",
      "File \u001b[0;32m~/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/nfs/home/seonbinara/lg_display_pj/training/full_MLP_regression.ipynb Cell 12'\u001b[0m in \u001b[0;36mFullWithVtMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacsys15.yonsei.ac.kr/nfs/home/seonbinara/lg_display_pj/training/full_MLP_regression.ipynb#ch0000011vscode-remote?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacsys15.yonsei.ac.kr/nfs/home/seonbinara/lg_display_pj/training/full_MLP_regression.ipynb#ch0000011vscode-remote?line=16'>17</a>\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacsys15.yonsei.ac.kr/nfs/home/seonbinara/lg_display_pj/training/full_MLP_regression.ipynb#ch0000011vscode-remote?line=17'>18</a>\u001b[0m \u001b[39m    Forward pass\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bacsys15.yonsei.ac.kr/nfs/home/seonbinara/lg_display_pj/training/full_MLP_regression.ipynb#ch0000011vscode-remote?line=18'>19</a>\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bacsys15.yonsei.ac.kr/nfs/home/seonbinara/lg_display_pj/training/full_MLP_regression.ipynb#ch0000011vscode-remote?line=19'>20</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///nfs/home/seonbinara/anaconda3/envs/lg_display/lib/python3.10/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the training loop\n",
    "for epoch in range(0, 100): # 20 epochs at maximum\n",
    "    \n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    \n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "    \n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Get and prepare inputs\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform forward pass\n",
    "        outputs = mlp(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "        \n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 1000 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                (i + 1, current_loss / 100*32))\n",
    "            current_loss = 0.0\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mlp.state_dict(), '../checkpoint/full_vt_mlp_model_nrmse.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.4321e+08, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "predictions = torch.tensor([], dtype=torch.float).to(device)\n",
    "actual = torch.tensor([], dtype=torch.float).to(device)\n",
    "with torch.no_grad():\n",
    "    mlp.eval()\n",
    "    for data in test_loader:\n",
    "        inputs, values = data\n",
    "        inputs, values = inputs.float().to(device), values.float().to(device)\n",
    "        values = values.reshape((values.shape[0], 1))\n",
    "\n",
    "        outputs = mlp(inputs)\n",
    "        predictions = torch.cat((predictions, outputs), 0)\n",
    "        actual = torch.cat((actual, values), 0)\n",
    "    \n",
    "# predictions = predictions.cpu().numpy()\n",
    "# actual = actual.cpu().numpy()\n",
    "\n",
    "eval_loss = NRMSELoss()\n",
    "\n",
    "nrmse = eval_loss(predictions, actual)\n",
    "\n",
    "print(nrmse)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3829caa72e4f00bfa838cc8791f96dc30ddd90ae454d4eaf3d8b7ab9877dcc00"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('lg_display')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
